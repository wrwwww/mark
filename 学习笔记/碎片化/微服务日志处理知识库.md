## 一、问题背景

在传统单体应用中，日志通常写入本机文件（如 `/var/log/...`）。  
在微服务 + 弹性伸缩环境中，如果依然使用本地文件，会遇到几个核心问题：

1. **日志分散**

- 每个实例只保存自己的日志。
- 实例缩容或被销毁时，日志可能丢失。

2. **排查困难**

- 服务有多个实例，不知道去哪个节点查看日志。
- 可能需要登录多台机器拼凑完整日志。

3. **存储与分析困难**

- 无统一日志收集方式，难以做全局检索、统计和告警。

---

## 二、业界常用日志处理方式

### 1. 本地文件 + 日志收集器（传统方式）

- 应用仍写本地日志文件（如 `logs/app.log`）。
- 在宿主机或容器里运行日志收集 Agent（Filebeat、Fluentd、Vector 等）。
- Agent 实时读取日志文件并发送到集中式日志系统（ELK、EFK、Loki、Splunk）。
- **优点**：应用无需修改，弹性伸缩不会影响日志集中存储。

### 2. 标准输出（stdout/stderr）+ 容器编排收集

- 微服务跑在 Kubernetes / Docker 上时，推荐直接写日志到 stdout。
- K8s / Docker 默认将容器 stdout/stderr 重定向到日志文件。
- 再用 Fluentd/Fluent Bit/Filebeat 从容器日志目录采集，并汇总到日志系统。
- **优点**：避免应用直接管理日志文件，实现容器无状态化。

### 3. 应用直写集中式系统

- 应用使用 SDK 将日志直接发送到 Kafka / Elasticsearch / Loki / 云日志服务。
- **适合**高并发场景，但会耦合应用与日志系统，解耦性较差。

### 4. 云原生日志服务

- AWS CloudWatch Logs、阿里云 SLS、腾讯云 CLS 等。
- 应用写 stdout 或文件，由 Agent 自动采集。
- **优点**：无需自行搭建 ELK，减少运维成本。

---

## 三、运维落地建议

1. **开发规范**

- 建议应用写日志到 stdout，不绑定本地文件。

2. **部署日志收集器**

- 在节点上统一部署 Agent（DaemonSet 模式），采集所有日志并发送到集中存储。

3. **日志系统选型**

- 开源方案：ELK（Elasticsearch + Logstash/Fluentd + Kibana）、EFK（Fluentd + ES + Kibana）、Loki + Grafana。
- 云服务：CloudWatch、阿里云 SLS、腾讯云 CLS。

4. **索引与检索**

- 按服务名、实例 ID、traceId、时间等维度区分，方便定位问题。

**总结一句话**

微服务 + 弹性伸缩环境下，日志不再只存储在单个实例，而是通过日志收集系统汇总到统一存储和检索平台。

---

## 四、腾讯云 CLS（Cloud Log Service）

### 1. CLS 简介

- 全托管日志服务：采集、存储、查询、分析、投递一体化。
- 类似阿里云 SLS / AWS CloudWatch Logs。
- 解决微服务多实例日志分散问题。

### 2. 核心功能

1. **日志采集**

- Agent（服务器/容器）、容器采集 stdout/stderr、SDK/API。
- 支持多格式日志（JSON、多行 Java 堆栈等）。

2. **日志存储**

- 数据存储在 Logset/Topic，支持自动分区与冷热分层。

3. **日志查询与分析**

- 类 SQL 查询（CLSQL）、关键字搜索、正则匹配、聚合分析。

4. **日志投递**

- 可投递至 COS、Kafka、ES 或 CLS 互投。

5. **告警与监控**

- 基于日志查询结果设置告警，支持短信/微信/钉钉通知。

### 3. 适用场景

- 微服务 / 容器日志集中管理
- 运维监控、故障排查
- 安全审计
- 大数据分析

### 4. 与自建 ELK 对比

|对比点|CLS|自建 ELK|
|---|---|---|
|部署|全托管，无需运维|自行搭建、运维|
|成本|按量计费|机器成本 + 运维成本|
|灵活性|功能固定，依赖云|高度可定制|
|运维压力|几乎无|集群维护复杂|

**总结**

CLS = 日志收集 + 存储 + 查询 + 分析 + 告警 的一站式平台，适合弹性伸缩场景。

---

## 五、自建 ELK / EFK

### 1. 架构组件

- Elasticsearch（存储与检索）
- Logstash / Fluentd / Filebeat（采集与转发）
- Kibana（可视化查询）

### 2. 部署步骤（Docker 示例）

```
# 创建网络
docker network create elk

# Elasticsearch
docker run -d --name elasticsearch --net elk \
  -e "discovery.type=single-node" \
  -e "ES_JAVA_OPTS=-Xms2g -Xmx2g" \
  -p 9200:9200 -p 9300:9300 \
  elasticsearch:8.14.0

# Kibana
docker run -d --name kibana --net elk \
  -e ELASTICSEARCH_HOSTS=http://elasticsearch:9200 \
  -p 5601:5601 \
  kibana:8.14.0

# Filebeat 配置示例
filebeat.inputs:
  - type: log
    paths:
      - /var/log/*.log
    fields:
      service: myapp
    fields_under_root: true

output.elasticsearch:
  hosts: ["http://<ES_IP>:9200"]
```

### 3. 优化与扩展

- 分布式 ES 集群，多节点部署（Master/Data/Ingest）。
- 高可用：副本、负载均衡。
- 存储优化：热/冷数据分层、定期清理。
- 安全：ES 用户认证、HTTPS、角色权限。

---

## 六、Kubernetes + Filebeat 日志采集（DaemonSet）

### 1. 安装方式

- **DaemonSet**（推荐）：每个节点一个 Filebeat Pod，采集节点上所有容器日志。
- **Sidecar**：每个业务 Pod 里额外跑 Filebeat，只采集该 Pod 日志，运维复杂。

### 2. DaemonSet 部署示例（Helm）

```
helm repo add elastic https://helm.elastic.co
helm repo update

helm install filebeat elastic/filebeat \
  --namespace kube-system \
  --set daemonset.enabled=true \
  --set output.elasticsearch.hosts=["http://<ES_IP>:9200"]
```

### 3. 配置示例

```
filebeatConfig:
  filebeat.yml: |
    filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/*.log
        processors:
          - add_kubernetes_metadata:
              in_cluster: true

    output.elasticsearch:
      hosts: ['http://elasticsearch:9200']
```

- `paths` 指向 K8s 容器日志目录。
- `add_kubernetes_metadata` 自动加 Pod 名称、命名空间等标签，便于搜索。

### 4. 验证

- 查看 Pod 状态：`kubectl get pods -n kube-system -l app=filebeat`
- 在 Kibana Discover 页面搜索日志，可按 `kubernetes.namespace` / `kubernetes.pod.name` 筛选。

---

## 七、总结落地方案

1. **应用** → 写 stdout 日志（容器无状态化）。
2. **日志采集** → K8s 节点部署 Filebeat DaemonSet 或使用云 CLS Agent。
3. **日志存储** → Elasticsearch / CLS。
4. **日志展示** → Kibana / Grafana / CLS 控制台。
5. **告警监控** → 根据关键字、聚合设置告警。

---

如果需要，我可以再帮你画一张 **微服务日志收集架构图**，直观展示日志从实例 → DaemonSet/Agent → Elasticsearch/CLS → 查询/告警的完整流程。

你希望我帮你画吗？